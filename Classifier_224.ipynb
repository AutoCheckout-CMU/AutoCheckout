{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "# torch.cuda.get_device_name(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "train_dir = 'data/classifier/train-224x224'\n",
    "test_composed_dir = 'data/classifier/test-224x224'\n",
    "test_real_dir = 'data/classifier/test-224x224-real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# client = MongoClient('mongodb://cpsweek:localdb@localhost:27018')\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "\n",
    "db = client['cps-test-01']\n",
    "\n",
    "# db.products\n",
    "class Product:\n",
    "    def __init__(self, barcode_type, id, name, thumbnail, price, weight):\n",
    "        self.barcode_type =barcode_type\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.thumbnail = thumbnail\n",
    "        self.price = price\n",
    "        self.weight = weight\n",
    "        self.plate_ids = None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"%s %s %s\\t%f %f %s %s\" % (self.barcode_type, self.id, self.name, self.price, self.weight, self.plate_ids, self.thumbnail)\n",
    "\n",
    "products_raw = db['products']\n",
    "products = {}\n",
    "\n",
    "\n",
    "for item in products_raw.find():\n",
    "    barcode_type = item['product_id']['barcode_type']\n",
    "    id = item['product_id']['id']\n",
    "    name = item['metadata']['name']\n",
    "    thumbnail = item['metadata']['thumbnail']\n",
    "    price = item['metadata']['price']\n",
    "    weight = item['metadata']['weight']\n",
    "    product = Product(barcode_type, id, name, thumbnail, price, weight)\n",
    "    products[id] = product\n",
    "#     print (product)\n",
    "print ('products', len(products))\n",
    "products[''] = Product('barcode_type', 'id', 'name', 'thumbnail', price=0, weight=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transforms.Compose([\n",
    "            transforms.Scale(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16, \n",
    "        shuffle=True,\n",
    "        num_workers=4)\n",
    "\n",
    "test_composed_dataset = datasets.ImageFolder(test_composed_dir, transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "test_composed_loader = torch.utils.data.DataLoader(\n",
    "        test_composed_dataset,\n",
    "        batch_size=1, \n",
    "        shuffle=False,\n",
    "        num_workers=1)\n",
    "\n",
    "test_real_dataset = datasets.ImageFolder(test_real_dir, transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "test_real_loader = torch.utils.data.DataLoader(\n",
    "        test_real_dataset,\n",
    "        batch_size=1, \n",
    "        shuffle=True,\n",
    "        num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def show_samples():\n",
    "    # get some random training images\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    imshow(torchvision.utils.make_grid(images[0]))\n",
    "    print(products[train_dataset.classes[labels[0]]])\n",
    "\n",
    "    # get some random composed test images\n",
    "    dataiter = iter(test_composed_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print(products[test_composed_dataset.classes[labels]])\n",
    "    \n",
    "    # get some random real test images\n",
    "    dataiter = iter(test_real_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print(products[test_real_dataset.classes[labels]])\n",
    "\n",
    "show_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "# torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # ->224 x 224\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, 2) # -> 110x110\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, 2) # -> 53x53\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5, 2) # -> 25x25\n",
    "        self.conv4 = nn.Conv2d(32, 32, 5, 2) # -> 11x11\n",
    "        self.conv5 = nn.Conv2d(32, 32, 2, 2) # -> 5x5\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 128) \n",
    "        self.fc2 = nn.Linear(128, 18)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# net = Net()\n",
    "net = models.mobilenet_v2(pretrained=True).to(device)\n",
    "# net[Linear-158] = nn.Linear()\n",
    "summary(net, input_size=(3, 224, 224))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train():\n",
    "    net.train()\n",
    "    start = time.time()\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        elapsed_time = time.time() - start\n",
    "        print('%d min [epoch %d, %d batches] loss: %.3f' %\n",
    "              (elapsed_time / 60, epoch + 1, len(train_loader), running_loss / len(train_loader)))\n",
    "\n",
    "    print('Finished Training')\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'data/classifier/mobilenet_224x224.model'\n",
    "# torch.save(net.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = test_composed_loader\n",
    "test_dataset = test_composed_dataset\n",
    "\n",
    "# testloader = test_real_loader\n",
    "# test_dataset = test_real_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = models.mobilenet_v2(pretrained=True).to(device)\n",
    "net.load_state_dict(torch.load(SAVE_PATH))\n",
    "\n",
    "# test images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print ('predicted')\n",
    "for pred in predicted:\n",
    "#     print (pred)\n",
    "#     print (train_dataset.classes[pred])\n",
    "    print (products[train_dataset.classes[pred]])\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images.cpu()))\n",
    "pdts = [products[test_dataset.classes[label]] for label in labels]\n",
    "print ('ground truth:\\n')\n",
    "for product in pdts:\n",
    "    print (product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "#         print (outputs.shape)\n",
    "        _, predicteds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "#         print (train_dataset.classes[predicted])\n",
    "#         print (test_dataset.classes[labels])\n",
    "#         print (predicteds)\n",
    "        for i in range(len(images)):\n",
    "            predicted = predicteds[i]\n",
    "            label = labels[i]\n",
    "           \n",
    "            predicted_barcode = train_dataset.classes[predicted]\n",
    "            groundtruth_barcode = test_dataset.classes[label]\n",
    "            print (predicted_barcode, groundtruth_barcode)\n",
    "            if (predicted_barcode == groundtruth_barcode):\n",
    "                correct += 1\n",
    "# \n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100.0 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
