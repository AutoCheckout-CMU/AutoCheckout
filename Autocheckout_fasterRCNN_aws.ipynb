{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jA9KjkzQqYu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# print (torch.cuda.current_device())\n",
    "# print (torch.cuda.device(torch.cuda.current_device()))\n",
    "print (torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lyRCvFEDHSCk"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# # drive.flush_and_unmount()\n",
    "# drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_crpZuTPQDkR"
   },
   "outputs": [],
   "source": [
    "# install dependencies: (use cu100 because colab is on CUDA 10.0)\n",
    "# !pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
    "# !pip install cython pyyaml==5.1\n",
    "# !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "import torch, torchvision\n",
    "print ('torch',torch.__version__)\n",
    "print ('torchvision',torchvision.__version__)\n",
    "# !gcc --version\n",
    "# opencv is pre-installed on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRjjUS1dQTr_"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/detectron2\n",
    "# !git clone https://github.com/tangsanli5201/DeepPCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKFNHUO2QnVr"
   },
   "outputs": [],
   "source": [
    "# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n",
    "\n",
    "# Mengmeng: cu100 means cuda v10.0? If have problem please install from source:\n",
    "# https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-R4nVxQ9arDS"
   },
   "outputs": [],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "# Some basic setup\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q35KxEiha-FW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import IPython\n",
    "def cv2_imshow(img):\n",
    "    img = img[:,:,[2,1,0]]\n",
    "    img = Image.fromarray(img)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1Vx4wOpIc_k"
   },
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog\n",
    "image_root_path = 'data/classifier/combined-4452'\n",
    "metadata_json_path = 'data/classifier/combined-4452/metadata_coco_format.json'\n",
    "detectron_output_dir = \"data/classifier/output\"\n",
    "\n",
    "DatasetCatalog._REGISTERED.clear()\n",
    "MetadataCatalog._NAME_TO_META.clear()\n",
    "register_coco_instances(\"my_dataset\", {}, metadata_json_path, image_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHas9kLJmii9"
   },
   "outputs": [],
   "source": [
    "#check dataset\n",
    "my_metadata = MetadataCatalog.get(\"my_dataset\")\n",
    "print(type(my_metadata))\n",
    "my_dataset = DatasetCatalog.get('my_dataset')\n",
    "for item in my_dataset:\n",
    "  print (item)\n",
    "  break\n",
    "    \n",
    "# TODO: Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGxmYFXQqYsD"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = detectron_output_dir\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset\",)\n",
    "# cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"  # Let training initialize from model zoo\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 2000 # checkpoint every 10min\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.02  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 60000    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 18 \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()\n",
    "#It will train about 30 minutes for 4000 iterations in AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9mwqHcwOZZV"
   },
   "outputs": [],
   "source": [
    "# ! pwd\n",
    "# ! ls \"drive/My Drive/Colab Notebooks/combined_219_images/data/classifier/combined/041364087320/041364087320_700.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3r9rHeQzxcsN"
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.001  # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"my_dataset\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIto29Kh5h_I"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "import random\n",
    "\n",
    "for d in random.sample(my_dataset, 10):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FyXbr19DC7On"
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# client = MongoClient('mongodb://cpsweek:localdb@localhost:27018')\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "\n",
    "db = client['cps-test-01']\n",
    "\n",
    "# db.products\n",
    "class Product:\n",
    "    def __init__(self, barcode_type, id, name, thumbnail, price, weight):\n",
    "        self.barcode_type =barcode_type\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.thumbnail = thumbnail\n",
    "        self.price = price\n",
    "        self.weight = weight\n",
    "        self.plate_ids = None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"%s %s %s\\t%f %f %s %s\" % (self.barcode_type, self.id, self.name, self.price, self.weight, self.plate_ids, self.thumbnail)\n",
    "\n",
    "products_raw = db['products']\n",
    "products = {}\n",
    "\n",
    "\n",
    "for item in products_raw.find():\n",
    "    barcode_type = item['product_id']['barcode_type']\n",
    "    id = item['product_id']['id']\n",
    "    name = item['metadata']['name']\n",
    "    thumbnail = item['metadata']['thumbnail']\n",
    "    price = item['metadata']['price']\n",
    "    weight = item['metadata']['weight']\n",
    "    product = Product(barcode_type, id, name, thumbnail, price, weight)\n",
    "    products[id] = product\n",
    "#     print (product)\n",
    "print ('products', len(products))\n",
    "products[''] = Product('barcode_type', 'id', 'name', 'thumbnail', price=0, weight=0) \n",
    "my_metadata = MetadataCatalog.get(\"my_dataset\")\n",
    "product_barcodes = my_metadata.thing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwuqvOGc5iRW"
   },
   "outputs": [],
   "source": [
    "# # images = ['data/others/m&m crop.png','data/others/m&m.png']\n",
    "# images = [\n",
    "#             'data/mengmeng-vision/1/input/original.png',\n",
    "#             'data/mengmeng-vision/1/input/bg_subtract.png',\n",
    "#             'data/mengmeng-vision/1/input/bg_subtract1.png',\n",
    "#             'data/mengmeng-vision/1/input/cropped.png',\n",
    "#             'data/mengmeng-vision/1/input/cropped2.png']\n",
    "images = [\n",
    "            'data/mengmeng-vision/1/input/test1.png',\n",
    "            'data/mengmeng-vision/1/input/test3.png',\n",
    "            'data/mengmeng-vision/1/input/test4.png']\n",
    "# for d in random.sample(my_dataset, 3):\n",
    "#     im = cv2.imread(d[\"file_name\"])\n",
    "\n",
    "for image in images:\n",
    "    im = cv2.imread(image)\n",
    "#     cv2_imshow(im)\n",
    "    outputs = predictor(im)\n",
    "    # print (outputs)\n",
    "    v = Visualizer(im,\n",
    "                   metadata=my_metadata, \n",
    "                   scale=0.8,\n",
    "                   instance_mode =  ColorMode.IMAGE\n",
    "        )\n",
    "                   # remove the colors of unsegmented pixels\n",
    "    print (outputs['instances'].scores[:5])\n",
    "    for i in range(len(outputs['instances'].pred_classes)):\n",
    "        pred_barcode = product_barcodes[outputs['instances'].pred_classes[i]]\n",
    "        score = outputs['instances'].scores[i]\n",
    "        pred_product = products[pred_barcode]\n",
    "#         print(pred_product)\n",
    "        print(\"%.0f%% %s %s: %s\" % (100 * score.to(\"cpu\").numpy(), pred_barcode, pred_product.name, pred_product.thumbnail))\n",
    "        if i>10:\n",
    "            break\n",
    "#         print(outputs[\"instances\"].pred_boxes)\n",
    "\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(v.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackgroundSubtractor:\n",
    "    def __init__(self):\n",
    "        self.knn = cv2.createBackgroundSubtractorKNN()\n",
    "        self.mog = cv2.bgsegm.createBackgroundSubtractorMOG() # 1st good\n",
    "        self.mog2 = cv2.createBackgroundSubtractorMOG2()\n",
    "        self.gsoc = cv2.bgsegm.createBackgroundSubtractorGSOC() # 2nd good\n",
    "        self.gmg = cv2.bgsegm.createBackgroundSubtractorGMG() # bad\n",
    "        self.kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        \n",
    "    def runKNN(self, frame):\n",
    "        return self.knn.apply(frame)\n",
    "\n",
    "    def runMOG(self, frame):\n",
    "        return self.mog.apply(frame)\n",
    "    \n",
    "    def runMOG2(self, frame):\n",
    "        return self.mog2.apply(frame)\n",
    "\n",
    "    def runGSOC(self, frame):\n",
    "        return self.gsoc.apply(frame)\n",
    "\n",
    "    def runGMG(self, frame):\n",
    "        mask = self.gmg.apply(frame)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, self.kernel)\n",
    "        return mask\n",
    "\n",
    "    def run(self, frame):\n",
    "        return self.runGSOC(frame)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNjYbtHL6lSy"
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import io\n",
    "from IPython.display import clear_output, Image as PILIMAGE, display, HTML\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(a)\n",
    "    a = a[:,:,[2,1,0]]\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(PILIMAGE(data=f.getvalue()))\n",
    "    \n",
    "# cam = cv2.VideoCapture(0)\n",
    "# cam = cv2.VideoCapture('data/public-dataset/192.168.1.103_2019-11-07_02-35-15.mp4')\n",
    "cam = cv2.VideoCapture('/home/ubuntu/git-clones/AutoCheckout-CMU-F4/data/mengmeng-vision/1/192.168.1.103_2019-11-07_02-41-17 +3m52 070462098617 Sour Patch Kids Peg .mp4')\n",
    "# cam = cv2.VideoCapture('data/mengmeng-vision/192.168.1.103_2019-11-07_02-41-17 +7m11 070462098617 Sour Patch Kids Peg .mp4')\n",
    "# cam = cv2.VideoCapture('data/mengmeng-vision/192.168.1.105_2019-11-07_02-41-16 6m08 084114033338 Kettle Chips Sea Salt & Vinegar None.mp4')\n",
    "\n",
    "backSub = BackgroundSubtractor()\n",
    "\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "success = True\n",
    "bg_subtraction = cv2.VideoWriter('/home/ubuntu/git-clones/AutoCheckout-CMU-F4/data/mengmeng-vision/1/bg_subtraction.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 10, (1280,720))\n",
    "identified = cv2.VideoWriter('/home/ubuntu/git-clones/AutoCheckout-CMU-F4/data/mengmeng-vision/1/identified.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 10, (1280,720))\n",
    "\n",
    "try:\n",
    "    while(success):\n",
    "        # Capture frame-by-frame\n",
    "        success, frame = cam.read()\n",
    "        if (frame is None):\n",
    "            continue\n",
    "\n",
    "        background_mask = backSub.run(frame)\n",
    "        frame = cv2.bitwise_and(frame, frame, mask=background_mask)\n",
    "        bg_subtraction.write(frame)\n",
    "#         cv2_imshow(frame)\n",
    "        outputs = predictor(frame)\n",
    "        for i in range(len(outputs['instances'].pred_classes)):\n",
    "            pred_barcode = product_barcodes[outputs['instances'].pred_classes[i]]\n",
    "            score = outputs['instances'].scores[i]\n",
    "            pred_product = products[pred_barcode]\n",
    "#             print(\"%f%% %s %s: %s\" % (100*score.to(\"cpu\").numpy(), pred_barcode, pred_product.name, pred_product.thumbnail))\n",
    "        \n",
    "        # We can use `Visualizer` to draw the predictions on the image.\n",
    "        v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        identified.write(v.get_image()[:, :, ::-1])\n",
    "#         showarray(v.get_image()[:, :, ::-1])\n",
    "#         frame_count += 1\n",
    "#         elapsed_time = time.time() - start_time # seconds\n",
    "#         print (int(frame_count/elapsed_time), 'fps')\n",
    "# #         # Display the frame until new frame is available\n",
    "#         clear_output(wait=True)\n",
    "#         break\n",
    "        \n",
    "    bg_subtraction.release()\n",
    "    identified.release()\n",
    "    cam.release()\n",
    "except KeyboardInterrupt:\n",
    "    bg_subtraction.release()\n",
    "    identified.release()\n",
    "    cam.release()\n",
    "#     out.release()\n",
    "    print (\"Stream stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autocheckout_fasterRCNN_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
